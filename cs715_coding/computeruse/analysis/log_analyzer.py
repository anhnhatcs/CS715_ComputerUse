#!/usr/bin/env python3
"""
Log analyzer for Claude Computer Use Demo
This script analyzes log files generated by the Streamlit application and creates summaries for evaluation.
"""

import os
import re
import json
import argparse
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
from collections import Counter
from computeruse.utils.utils import Task, Step, get_unique_task_id

def parse_log_file(log_path):
    """Parse a log file and extract structured data."""
    data = []
    
    with open(log_path, 'r') as f:
        log_content = f.read()
    
    # Extract all log entries
    log_entries = re.findall(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}) \[(\w+)\] (.*)', log_content)
    
    for timestamp, level, message in log_entries:
        entry = {
            'timestamp': datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S,%f'),
            'level': level,
            'message': message
        }
        
        # Extract specific data based on message patterns
        if 'User entered instruction:' in message:
            entry['type'] = 'user_instruction'
            entry['instruction'] = message.replace('User entered instruction: ', '')
        
        elif 'Run button clicked with instruction:' in message:
            entry['type'] = 'run_button'
            entry['instruction'] = re.search(r"Run button clicked with instruction: '(.*)'", message).group(1)
        
        elif 'Assistant output:' in message:
            entry['type'] = 'assistant_output'
            entry['output'] = message.replace('Assistant output: ', '')
        
        elif 'Tool Output' in message:
            entry['type'] = 'tool_output'
            match = re.search(r"> Tool Output \[(.*?)\]: (.*)", message)
            if match:
                entry['tool_id'] = match.group(1)
                entry['output'] = match.group(2)
        
        elif 'Tool called:' in message:
            entry['type'] = 'tool_call'
            match = re.search(r"Tool called: \[(.*?)\] (.*?) with args: (.*)", message)
            if match:
                entry['tool_id'] = match.group(1)
                entry['tool_name'] = match.group(2)
                entry['args'] = match.group(3)
        
        data.append(entry)
    
    return data

def analyze_log(log_data):
    """Analyze log data and compute statistics."""
    df = pd.DataFrame(log_data)
    
    # Basic statistics
    stats = {
        'total_entries': len(df),
        'user_instructions': len(df[df['type'] == 'user_instruction']),
        'assistant_outputs': len(df[df['type'] == 'assistant_output']),
        'tool_calls': len(df[df['type'] == 'tool_call']),
        'tool_outputs': len(df[df['type'] == 'tool_output']),
    }
    
    # Tool usage analysis
    if 'tool_name' in df.columns:
        tool_usage = Counter(df[df['type'] == 'tool_call']['tool_name'])
        stats['tool_usage'] = dict(tool_usage)
    
    # Timeline analysis
    if 'timestamp' in df.columns:
        df['hour'] = df['timestamp'].dt.hour
        hourly_activity = df.groupby('hour').size()
        stats['hourly_activity'] = dict(zip(hourly_activity.index, hourly_activity.values))
    
    return stats

def visualize_stats(stats, output_dir=None):
    """Visualize the log statistics."""
    # Tool usage pie chart
    if 'tool_usage' in stats and stats['tool_usage']:
        plt.figure(figsize=(10, 6))
        tools = list(stats['tool_usage'].keys())
        counts = list(stats['tool_usage'].values())
        plt.pie(counts, labels=tools, autopct='%1.1f%%')
        plt.title('Tool Usage Distribution')
        
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)
            plt.savefig(os.path.join(output_dir, 'tool_usage_pie.png'))
        else:
            plt.show()
    
    # Hourly activity bar chart
    if 'hourly_activity' in stats and stats['hourly_activity']:
        plt.figure(figsize=(12, 6))
        hours = list(stats['hourly_activity'].keys())
        activity = list(stats['hourly_activity'].values())
        plt.bar(hours, activity)
        plt.xlabel('Hour of Day')
        plt.ylabel('Number of Actions')
        plt.title('Activity by Hour')
        plt.xticks(range(0, 24))
        plt.grid(axis='y', linestyle='--', alpha=0.7)
        
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)
            plt.savefig(os.path.join(output_dir, 'hourly_activity.png'))
        else:
            plt.show()

def generate_report(stats, log_path, output_dir=None):
    """Generate a text report from the statistics."""
    report = f"Log Analysis Report for {os.path.basename(log_path)}\n"
    report += "=" * 50 + "\n\n"
    
    report += "Basic Statistics:\n"
    report += f"- Total Log Entries: {stats['total_entries']}\n"
    report += f"- User Instructions: {stats['user_instructions']}\n"
    report += f"- Assistant Outputs: {stats['assistant_outputs']}\n"
    report += f"- Tool Calls: {stats['tool_calls']}\n"
    report += f"- Tool Outputs: {stats['tool_outputs']}\n\n"
    
    if 'tool_usage' in stats and stats['tool_usage']:
        report += "Tool Usage:\n"
        for tool, count in stats['tool_usage'].items():
            report += f"- {tool}: {count} calls\n"
    
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        report_path = os.path.join(output_dir, f"report_{os.path.splitext(os.path.basename(log_path))[0]}.txt")
        with open(report_path, 'w') as f:
            f.write(report)
        return report_path
    else:
        return report

def parse_json_log(json_log_path):
    """Parse a JSON log file and extract task and step information."""
    try:
        with open(json_log_path, 'r') as f:
            log_data = json.load(f)
        
        # Extract task information
        task_id = log_data.get("session_id", "unknown")
        category = "unknown"
        test_id = "unknown"
        
        # Look for session metadata
        for event in log_data.get("events", []):
            if event.get("type") == "session_metadata":
                metadata = event.get("data", {})
                if "Cat" in metadata:
                    category = metadata["Cat"]
                if "Test_ID" in metadata:
                    test_id = metadata["Test_ID"]
        
        # Extract user instruction
        instruction = ""
        for event in log_data.get("events", []):
            if event.get("type") == "user_input":
                data = event.get("data", {})
                if "instruction" in data:
                    instruction = data["instruction"]
                    break
        
        # Create a Task object
        task = Task(
            id=task_id,
            category=category,
            test_id=test_id,
            instruction=instruction,
            steps=[],
            log_path=json_log_path
        )
        
        # Extract steps
        steps = extract_steps_from_json(log_data)
        task.steps = steps
        
        return task
    
    except Exception as e:
        print(f"Error parsing JSON log: {e}")
        return None

def extract_steps_from_json(log_data):
    """Extract steps from JSON log data."""
    steps = []
    tool_calls = []
    
    # Process events in chronological order
    for event in log_data.get("events", []):
        event_type = event.get("type")
        
        # Handle API responses (assistant actions)
        if event_type == "api_response":
            content = event.get("data", {}).get("content", [])
            
            for item in content:
                item_type = item.get("type")
                
                # Handle tool uses
                if item_type == "tool_use":
                    tool_id = item.get("id")
                    tool_name = item.get("name")
                    input_data = item.get("input", {})
                    
                    # Store tool call for later matching with results
                    tool_calls.append({
                        "id": tool_id,
                        "name": tool_name,
                        "input": input_data,
                        "timestamp": event.get("timestamp")
                    })
        
        # Handle tool results
        elif event_type == "tool_result":
            tool_use_id = event.get("data", {}).get("tool_use_id")
            result = event.get("data", {})
            
            # Find matching tool call
            matching_call = next((call for call in tool_calls if call["id"] == tool_use_id), None)
            
            if matching_call:
                # Create a step
                step = Step(
                    tool_name=matching_call["name"],
                    tool_input=matching_call["input"],
                    tool_output=result,
                    success="error" not in result,
                    timestamp=matching_call["timestamp"],
                    efficiency=None  # Efficiency will be determined during evaluation
                )
                
                steps.append(step)
                # Remove processed tool call
                tool_calls = [call for call in tool_calls if call["id"] != tool_use_id]
    
    return steps

def main():
    """Main function to process log files."""
    parser = argparse.ArgumentParser(description='Log analyzer for Claude Computer Use Demo')
    parser.add_argument('log_path', help='Path to the log file')
    parser.add_argument('--output-dir', help='Directory to save the output files')
    parser.add_argument('--json', action='store_true', help='Parse a JSON log file instead of a text log')
    args = parser.parse_args()
    
    if args.json:
        task = parse_json_log(args.log_path)
        if task:
            print(f"Task ID: {task.id}")
            print(f"Category: {task.category}")
            print(f"Test ID: {task.test_id}")
            print(f"Instruction: {task.instruction}")
            print(f"Steps: {len(task.steps)}")
            
            # You can add more detailed output or visualization for steps
    else:
        log_data = parse_log_file(args.log_path)
        stats = analyze_log(log_data)
        
        print(generate_report(stats, args.log_path))
        visualize_stats(stats, args.output_dir)

if __name__ == "__main__":
    main()
